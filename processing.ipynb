{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf8477a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b83851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e488ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ed43029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import Network\n",
    "from utils import train, save_model, test_accuracy, test_batch, test_classes, image_show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d0240",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83dc0917",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bfaff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "NUMBER_OF_LABELS = 10\n",
    "\n",
    "train_set = CIFAR10(root='./data', train=True, transform=transformations, download=True)\n",
    "test_set = CIFAR10(root='./data', train=False, transform=transformations, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ['airplane', 'automibile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7309b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c315ef6",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "463dc56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_loader = DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0)\n",
    "im = next(iter(viz_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28ad5df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf32330b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_show(torchvision.utils.make_grid(im[0]), label=classes[im[1].item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bc50ca",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e83b5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on  cuda:0  device\n",
      "[1,  1000] loss: 1.622\n",
      "[1,  2000] loss: 1.263\n",
      "[1,  3000] loss: 1.131\n",
      "For epoch 1 the test accuracy over the whole test set is 62 %\n",
      "[2,  1000] loss: 1.068\n",
      "[2,  2000] loss: 0.972\n",
      "[2,  3000] loss: 0.946\n",
      "For epoch 2 the test accuracy over the whole test set is 67 %\n",
      "[3,  1000] loss: 0.902\n",
      "[3,  2000] loss: 0.856\n",
      "[3,  3000] loss: 0.844\n",
      "For epoch 3 the test accuracy over the whole test set is 68 %\n",
      "[4,  1000] loss: 0.809\n",
      "[4,  2000] loss: 0.774\n",
      "[4,  3000] loss: 0.767\n",
      "For epoch 4 the test accuracy over the whole test set is 67 %\n",
      "[5,  1000] loss: 0.741\n",
      "[5,  2000] loss: 0.716\n",
      "[5,  3000] loss: 0.707\n",
      "For epoch 5 the test accuracy over the whole test set is 67 %\n",
      "[6,  1000] loss: 0.692\n",
      "[6,  2000] loss: 0.662\n",
      "[6,  3000] loss: 0.655\n",
      "For epoch 6 the test accuracy over the whole test set is 67 %\n",
      "[7,  1000] loss: 0.649\n",
      "[7,  2000] loss: 0.616\n",
      "[7,  3000] loss: 0.611\n",
      "For epoch 7 the test accuracy over the whole test set is 67 %\n",
      "[8,  1000] loss: 0.602\n",
      "[8,  2000] loss: 0.579\n",
      "[8,  3000] loss: 0.575\n",
      "For epoch 8 the test accuracy over the whole test set is 68 %\n",
      "[9,  1000] loss: 0.561\n",
      "[9,  2000] loss: 0.543\n",
      "[9,  3000] loss: 0.540\n",
      "For epoch 9 the test accuracy over the whole test set is 66 %\n",
      "[10,  1000] loss: 0.525\n",
      "[10,  2000] loss: 0.513\n",
      "[10,  3000] loss: 0.511\n",
      "For epoch 10 the test accuracy over the whole test set is 66 %\n",
      "[11,  1000] loss: 0.492\n",
      "[11,  2000] loss: 0.490\n",
      "[11,  3000] loss: 0.480\n",
      "For epoch 11 the test accuracy over the whole test set is 66 %\n",
      "[12,  1000] loss: 0.466\n",
      "[12,  2000] loss: 0.457\n",
      "[12,  3000] loss: 0.454\n",
      "For epoch 12 the test accuracy over the whole test set is 66 %\n",
      "[13,  1000] loss: 0.446\n",
      "[13,  2000] loss: 0.434\n",
      "[13,  3000] loss: 0.429\n",
      "For epoch 13 the test accuracy over the whole test set is 65 %\n",
      "[14,  1000] loss: 0.424\n",
      "[14,  2000] loss: 0.409\n",
      "[14,  3000] loss: 0.404\n",
      "For epoch 14 the test accuracy over the whole test set is 65 %\n",
      "[15,  1000] loss: 0.401\n",
      "[15,  2000] loss: 0.383\n",
      "[15,  3000] loss: 0.382\n",
      "For epoch 15 the test accuracy over the whole test set is 64 %\n",
      "[16,  1000] loss: 0.391\n",
      "[16,  2000] loss: 0.373\n",
      "[16,  3000] loss: 0.372\n",
      "For epoch 16 the test accuracy over the whole test set is 64 %\n",
      "[17,  1000] loss: 0.375\n",
      "[17,  2000] loss: 0.353\n",
      "[17,  3000] loss: 0.358\n",
      "For epoch 17 the test accuracy over the whole test set is 65 %\n",
      "[18,  1000] loss: 0.365\n",
      "[18,  2000] loss: 0.339\n",
      "[18,  3000] loss: 0.341\n",
      "For epoch 18 the test accuracy over the whole test set is 64 %\n",
      "[19,  1000] loss: 0.355\n",
      "[19,  2000] loss: 0.319\n",
      "[19,  3000] loss: 0.332\n",
      "For epoch 19 the test accuracy over the whole test set is 64 %\n",
      "[20,  1000] loss: 0.345\n",
      "[20,  2000] loss: 0.306\n",
      "[20,  3000] loss: 0.318\n",
      "For epoch 20 the test accuracy over the whole test set is 65 %\n",
      "[21,  1000] loss: 0.319\n",
      "[21,  2000] loss: 0.293\n",
      "[21,  3000] loss: 0.306\n",
      "For epoch 21 the test accuracy over the whole test set is 64 %\n",
      "[22,  1000] loss: 0.313\n",
      "[22,  2000] loss: 0.293\n",
      "[22,  3000] loss: 0.289\n",
      "For epoch 22 the test accuracy over the whole test set is 65 %\n",
      "[23,  1000] loss: 0.296\n",
      "[23,  2000] loss: 0.281\n",
      "[23,  3000] loss: 0.273\n",
      "For epoch 23 the test accuracy over the whole test set is 65 %\n",
      "[24,  1000] loss: 0.291\n",
      "[24,  2000] loss: 0.276\n",
      "[24,  3000] loss: 0.276\n",
      "For epoch 24 the test accuracy over the whole test set is 65 %\n",
      "[25,  1000] loss: 0.273\n",
      "[25,  2000] loss: 0.263\n",
      "[25,  3000] loss: 0.260\n",
      "For epoch 25 the test accuracy over the whole test set is 64 %\n",
      "[26,  1000] loss: 0.270\n",
      "[26,  2000] loss: 0.258\n",
      "[26,  3000] loss: 0.249\n",
      "For epoch 26 the test accuracy over the whole test set is 64 %\n",
      "[27,  1000] loss: 0.256\n",
      "[27,  2000] loss: 0.255\n",
      "[27,  3000] loss: 0.250\n",
      "For epoch 27 the test accuracy over the whole test set is 65 %\n",
      "[28,  1000] loss: 0.247\n",
      "[28,  2000] loss: 0.251\n",
      "[28,  3000] loss: 0.236\n",
      "For epoch 28 the test accuracy over the whole test set is 65 %\n",
      "[29,  1000] loss: 0.254\n",
      "[29,  2000] loss: 0.219\n",
      "[29,  3000] loss: 0.230\n",
      "For epoch 29 the test accuracy over the whole test set is 66 %\n",
      "[30,  1000] loss: 0.248\n",
      "[30,  2000] loss: 0.218\n",
      "[30,  3000] loss: 0.231\n",
      "For epoch 30 the test accuracy over the whole test set is 65 %\n",
      "[31,  1000] loss: 0.230\n",
      "[31,  2000] loss: 0.223\n",
      "[31,  3000] loss: 0.206\n",
      "For epoch 31 the test accuracy over the whole test set is 64 %\n",
      "[32,  1000] loss: 0.239\n",
      "[32,  2000] loss: 0.210\n",
      "[32,  3000] loss: 0.218\n",
      "For epoch 32 the test accuracy over the whole test set is 64 %\n",
      "[33,  1000] loss: 0.216\n",
      "[33,  2000] loss: 0.206\n",
      "[33,  3000] loss: 0.227\n",
      "For epoch 33 the test accuracy over the whole test set is 63 %\n",
      "[34,  1000] loss: 0.212\n",
      "[34,  2000] loss: 0.204\n",
      "[34,  3000] loss: 0.205\n",
      "For epoch 34 the test accuracy over the whole test set is 65 %\n",
      "[35,  1000] loss: 0.214\n",
      "[35,  2000] loss: 0.203\n",
      "[35,  3000] loss: 0.204\n",
      "For epoch 35 the test accuracy over the whole test set is 64 %\n",
      "[36,  1000] loss: 0.205\n",
      "[36,  2000] loss: 0.203\n",
      "[36,  3000] loss: 0.202\n",
      "For epoch 36 the test accuracy over the whole test set is 65 %\n",
      "[37,  1000] loss: 0.206\n",
      "[37,  2000] loss: 0.186\n",
      "[37,  3000] loss: 0.196\n",
      "For epoch 37 the test accuracy over the whole test set is 65 %\n",
      "[38,  1000] loss: 0.201\n",
      "[38,  2000] loss: 0.185\n",
      "[38,  3000] loss: 0.200\n",
      "For epoch 38 the test accuracy over the whole test set is 64 %\n",
      "[39,  1000] loss: 0.196\n",
      "[39,  2000] loss: 0.188\n",
      "[39,  3000] loss: 0.192\n",
      "For epoch 39 the test accuracy over the whole test set is 65 %\n",
      "[40,  1000] loss: 0.204\n",
      "[40,  2000] loss: 0.179\n",
      "[40,  3000] loss: 0.178\n",
      "For epoch 40 the test accuracy over the whole test set is 64 %\n",
      "[41,  1000] loss: 0.183\n",
      "[41,  2000] loss: 0.175\n",
      "[41,  3000] loss: 0.190\n",
      "For epoch 41 the test accuracy over the whole test set is 65 %\n",
      "[42,  1000] loss: 0.181\n",
      "[42,  2000] loss: 0.181\n",
      "[42,  3000] loss: 0.175\n",
      "For epoch 42 the test accuracy over the whole test set is 65 %\n",
      "[43,  1000] loss: 0.177\n",
      "[43,  2000] loss: 0.177\n",
      "[43,  3000] loss: 0.175\n",
      "For epoch 43 the test accuracy over the whole test set is 64 %\n",
      "[44,  1000] loss: 0.178\n",
      "[44,  2000] loss: 0.170\n",
      "[44,  3000] loss: 0.175\n",
      "For epoch 44 the test accuracy over the whole test set is 64 %\n",
      "[45,  1000] loss: 0.181\n",
      "[45,  2000] loss: 0.172\n",
      "[45,  3000] loss: 0.178\n",
      "For epoch 45 the test accuracy over the whole test set is 65 %\n",
      "[46,  1000] loss: 0.172\n",
      "[46,  2000] loss: 0.164\n",
      "[46,  3000] loss: 0.168\n",
      "For epoch 46 the test accuracy over the whole test set is 64 %\n",
      "[47,  1000] loss: 0.175\n",
      "[47,  2000] loss: 0.149\n",
      "[47,  3000] loss: 0.169\n",
      "For epoch 47 the test accuracy over the whole test set is 64 %\n",
      "[48,  1000] loss: 0.173\n",
      "[48,  2000] loss: 0.166\n",
      "[48,  3000] loss: 0.168\n",
      "For epoch 48 the test accuracy over the whole test set is 65 %\n",
      "[49,  1000] loss: 0.158\n",
      "[49,  2000] loss: 0.169\n",
      "[49,  3000] loss: 0.150\n",
      "For epoch 49 the test accuracy over the whole test set is 64 %\n",
      "[50,  1000] loss: 0.165\n",
      "[50,  2000] loss: 0.163\n",
      "[50,  3000] loss: 0.153\n",
      "For epoch 50 the test accuracy over the whole test set is 65 %\n",
      "[51,  1000] loss: 0.166\n",
      "[51,  2000] loss: 0.152\n",
      "[51,  3000] loss: 0.143\n",
      "For epoch 51 the test accuracy over the whole test set is 65 %\n",
      "[52,  1000] loss: 0.173\n",
      "[52,  2000] loss: 0.152\n",
      "[52,  3000] loss: 0.160\n",
      "For epoch 52 the test accuracy over the whole test set is 65 %\n",
      "[53,  1000] loss: 0.162\n",
      "[53,  2000] loss: 0.151\n",
      "[53,  3000] loss: 0.158\n",
      "For epoch 53 the test accuracy over the whole test set is 65 %\n",
      "[54,  1000] loss: 0.159\n",
      "[54,  2000] loss: 0.156\n",
      "[54,  3000] loss: 0.159\n",
      "For epoch 54 the test accuracy over the whole test set is 64 %\n",
      "[55,  1000] loss: 0.156\n",
      "[55,  2000] loss: 0.152\n",
      "[55,  3000] loss: 0.148\n",
      "For epoch 55 the test accuracy over the whole test set is 65 %\n",
      "[56,  1000] loss: 0.152\n",
      "[56,  2000] loss: 0.149\n",
      "[56,  3000] loss: 0.157\n",
      "For epoch 56 the test accuracy over the whole test set is 65 %\n",
      "[57,  1000] loss: 0.154\n",
      "[57,  2000] loss: 0.139\n",
      "[57,  3000] loss: 0.145\n",
      "For epoch 57 the test accuracy over the whole test set is 65 %\n",
      "[58,  1000] loss: 0.157\n",
      "[58,  2000] loss: 0.152\n",
      "[58,  3000] loss: 0.144\n",
      "For epoch 58 the test accuracy over the whole test set is 65 %\n",
      "[59,  1000] loss: 0.151\n",
      "[59,  2000] loss: 0.139\n",
      "[59,  3000] loss: 0.147\n",
      "For epoch 59 the test accuracy over the whole test set is 64 %\n",
      "[60,  1000] loss: 0.144\n",
      "[60,  2000] loss: 0.152\n",
      "[60,  3000] loss: 0.144\n",
      "For epoch 60 the test accuracy over the whole test set is 64 %\n",
      "[61,  1000] loss: 0.156\n",
      "[61,  2000] loss: 0.138\n",
      "[61,  3000] loss: 0.148\n",
      "For epoch 61 the test accuracy over the whole test set is 65 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62,  1000] loss: 0.146\n",
      "[62,  2000] loss: 0.137\n",
      "[62,  3000] loss: 0.147\n",
      "For epoch 62 the test accuracy over the whole test set is 65 %\n",
      "[63,  1000] loss: 0.147\n",
      "[63,  2000] loss: 0.139\n",
      "[63,  3000] loss: 0.134\n",
      "For epoch 63 the test accuracy over the whole test set is 64 %\n",
      "[64,  1000] loss: 0.149\n",
      "[64,  2000] loss: 0.131\n",
      "[64,  3000] loss: 0.149\n",
      "For epoch 64 the test accuracy over the whole test set is 64 %\n",
      "[65,  1000] loss: 0.161\n",
      "[65,  2000] loss: 0.140\n",
      "[65,  3000] loss: 0.132\n",
      "For epoch 65 the test accuracy over the whole test set is 65 %\n",
      "[66,  1000] loss: 0.139\n",
      "[66,  2000] loss: 0.147\n",
      "[66,  3000] loss: 0.133\n",
      "For epoch 66 the test accuracy over the whole test set is 65 %\n",
      "[67,  1000] loss: 0.149\n",
      "[67,  2000] loss: 0.125\n",
      "[67,  3000] loss: 0.137\n",
      "For epoch 67 the test accuracy over the whole test set is 65 %\n",
      "[68,  1000] loss: 0.148\n",
      "[68,  2000] loss: 0.137\n",
      "[68,  3000] loss: 0.143\n",
      "For epoch 68 the test accuracy over the whole test set is 65 %\n",
      "[69,  1000] loss: 0.136\n",
      "[69,  2000] loss: 0.152\n",
      "[69,  3000] loss: 0.133\n",
      "For epoch 69 the test accuracy over the whole test set is 65 %\n",
      "[70,  1000] loss: 0.137\n",
      "[70,  2000] loss: 0.130\n",
      "[70,  3000] loss: 0.137\n",
      "For epoch 70 the test accuracy over the whole test set is 65 %\n",
      "[71,  1000] loss: 0.146\n",
      "[71,  2000] loss: 0.130\n",
      "[71,  3000] loss: 0.136\n",
      "For epoch 71 the test accuracy over the whole test set is 65 %\n",
      "[72,  1000] loss: 0.136\n",
      "[72,  2000] loss: 0.128\n",
      "[72,  3000] loss: 0.139\n",
      "For epoch 72 the test accuracy over the whole test set is 64 %\n",
      "[73,  1000] loss: 0.134\n",
      "[73,  2000] loss: 0.138\n",
      "[73,  3000] loss: 0.135\n",
      "For epoch 73 the test accuracy over the whole test set is 65 %\n",
      "[74,  1000] loss: 0.142\n",
      "[74,  2000] loss: 0.137\n",
      "[74,  3000] loss: 0.129\n",
      "For epoch 74 the test accuracy over the whole test set is 65 %\n",
      "[75,  1000] loss: 0.130\n",
      "[75,  2000] loss: 0.130\n",
      "[75,  3000] loss: 0.135\n",
      "For epoch 75 the test accuracy over the whole test set is 65 %\n",
      "[76,  1000] loss: 0.139\n",
      "[76,  2000] loss: 0.126\n",
      "[76,  3000] loss: 0.131\n",
      "For epoch 76 the test accuracy over the whole test set is 64 %\n",
      "[77,  1000] loss: 0.135\n",
      "[77,  2000] loss: 0.126\n",
      "[77,  3000] loss: 0.138\n",
      "For epoch 77 the test accuracy over the whole test set is 64 %\n",
      "[78,  1000] loss: 0.132\n",
      "[78,  2000] loss: 0.134\n",
      "[78,  3000] loss: 0.130\n",
      "For epoch 78 the test accuracy over the whole test set is 65 %\n",
      "[79,  1000] loss: 0.130\n",
      "[79,  2000] loss: 0.125\n",
      "[79,  3000] loss: 0.131\n",
      "For epoch 79 the test accuracy over the whole test set is 65 %\n",
      "[80,  1000] loss: 0.135\n",
      "[80,  2000] loss: 0.129\n",
      "[80,  3000] loss: 0.127\n",
      "For epoch 80 the test accuracy over the whole test set is 65 %\n",
      "[81,  1000] loss: 0.136\n",
      "[81,  2000] loss: 0.122\n",
      "[81,  3000] loss: 0.138\n",
      "For epoch 81 the test accuracy over the whole test set is 64 %\n",
      "[82,  1000] loss: 0.135\n",
      "[82,  2000] loss: 0.128\n",
      "[82,  3000] loss: 0.125\n",
      "For epoch 82 the test accuracy over the whole test set is 65 %\n",
      "[83,  1000] loss: 0.133\n",
      "[83,  2000] loss: 0.127\n",
      "[83,  3000] loss: 0.126\n",
      "For epoch 83 the test accuracy over the whole test set is 65 %\n",
      "[84,  1000] loss: 0.139\n",
      "[84,  2000] loss: 0.130\n",
      "[84,  3000] loss: 0.130\n",
      "For epoch 84 the test accuracy over the whole test set is 65 %\n",
      "[85,  1000] loss: 0.135\n",
      "[85,  2000] loss: 0.126\n",
      "[85,  3000] loss: 0.126\n",
      "For epoch 85 the test accuracy over the whole test set is 64 %\n",
      "[86,  1000] loss: 0.130\n",
      "[86,  2000] loss: 0.125\n",
      "[86,  3000] loss: 0.119\n",
      "For epoch 86 the test accuracy over the whole test set is 64 %\n",
      "[87,  1000] loss: 0.134\n",
      "[87,  2000] loss: 0.131\n",
      "[87,  3000] loss: 0.128\n",
      "For epoch 87 the test accuracy over the whole test set is 64 %\n",
      "[88,  1000] loss: 0.137\n",
      "[88,  2000] loss: 0.124\n",
      "[88,  3000] loss: 0.120\n",
      "For epoch 88 the test accuracy over the whole test set is 65 %\n",
      "[89,  1000] loss: 0.127\n",
      "[89,  2000] loss: 0.124\n",
      "[89,  3000] loss: 0.131\n",
      "For epoch 89 the test accuracy over the whole test set is 64 %\n",
      "[90,  1000] loss: 0.122\n",
      "[90,  2000] loss: 0.116\n",
      "[90,  3000] loss: 0.116\n",
      "For epoch 90 the test accuracy over the whole test set is 64 %\n",
      "[91,  1000] loss: 0.142\n",
      "[91,  2000] loss: 0.127\n",
      "[91,  3000] loss: 0.126\n",
      "For epoch 91 the test accuracy over the whole test set is 65 %\n",
      "[92,  1000] loss: 0.120\n",
      "[92,  2000] loss: 0.122\n",
      "[92,  3000] loss: 0.130\n",
      "For epoch 92 the test accuracy over the whole test set is 65 %\n",
      "[93,  1000] loss: 0.131\n",
      "[93,  2000] loss: 0.114\n",
      "[93,  3000] loss: 0.129\n",
      "For epoch 93 the test accuracy over the whole test set is 65 %\n",
      "[94,  1000] loss: 0.126\n",
      "[94,  2000] loss: 0.121\n",
      "[94,  3000] loss: 0.125\n",
      "For epoch 94 the test accuracy over the whole test set is 65 %\n",
      "[95,  1000] loss: 0.134\n",
      "[95,  2000] loss: 0.121\n",
      "[95,  3000] loss: 0.120\n",
      "For epoch 95 the test accuracy over the whole test set is 65 %\n",
      "[96,  1000] loss: 0.127\n",
      "[96,  2000] loss: 0.123\n",
      "[96,  3000] loss: 0.120\n",
      "For epoch 96 the test accuracy over the whole test set is 65 %\n",
      "[97,  1000] loss: 0.121\n",
      "[97,  2000] loss: 0.126\n",
      "[97,  3000] loss: 0.126\n",
      "For epoch 97 the test accuracy over the whole test set is 64 %\n",
      "[98,  1000] loss: 0.126\n",
      "[98,  2000] loss: 0.121\n",
      "[98,  3000] loss: 0.115\n",
      "For epoch 98 the test accuracy over the whole test set is 65 %\n",
      "[99,  1000] loss: 0.125\n",
      "[99,  2000] loss: 0.133\n",
      "[99,  3000] loss: 0.122\n",
      "For epoch 99 the test accuracy over the whole test set is 64 %\n",
      "[100,  1000] loss: 0.112\n",
      "[100,  2000] loss: 0.123\n",
      "[100,  3000] loss: 0.130\n",
      "For epoch 100 the test accuracy over the whole test set is 64 %\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, test_loader, NUM_EPOCHS, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b6c277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
